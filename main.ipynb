{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6730fecf",
   "metadata": {},
   "source": [
    "## Assignment 3 Group 3\n",
    "### Zhengjie Deng a1865926\n",
    "### Harsh Mukeshkumar Gandhi a1879980\n",
    "### Wei You a1728091"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8516517",
   "metadata": {},
   "source": [
    "#### Dependency version:\n",
    "- Python: 3.8.16\n",
    "- pandas: 1.4.2\n",
    "- sklearn: 1.0.2\n",
    "- nltk: 3.7\n",
    "- tqdm: 4.64.1\n",
    "- matplotlib: 3.7.0\n",
    "- spacy: 3.5.0\n",
    "- numpy: 1.23.5\n",
    "- gensim: 3.8.3\n",
    "- pytorch: 2.0.0\n",
    "- pyserini: 0.21.0\n",
    "- transformers: 4.27.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b86ebdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 10.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from en-core-web-sm==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.6.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.5)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jackdeng/opt/anaconda3/envs/nlp-assignment1/lib/python3.8/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import gensim.downloader as api\n",
    "import warnings\n",
    "\n",
    "# might need to restart the kernel after insatll pyserini\n",
    "%pip install pyserini\n",
    "%pip install transformers\n",
    "\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Download en_core_web_lg model\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "# Download the pre-trained GloVe model\n",
    "glove_model = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "# ignore the warning\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2aac6",
   "metadata": {},
   "source": [
    "### 1. Reading dataset and pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5cff880",
   "metadata": {},
   "source": [
    "#### 1.1 Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e967e07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gx/nqfl1mhx0kg_s6zd6lgp6rb00000gn/T/ipykernel_41512/345416390.py:5: DtypeWarning: Columns (1,4,5,6,13,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f_metadata_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>pdf_json_files</th>\n",
       "      <th>pmc_json_files</th>\n",
       "      <th>url</th>\n",
       "      <th>s2_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ug7v899j</td>\n",
       "      <td>d1aafb70c066a2068b02786f8929fd9c900897fb</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
       "      <td>10.1186/1471-2334-1-6</td>\n",
       "      <td>PMC35282</td>\n",
       "      <td>11472636</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>OBJECTIVE: This retrospective chart review des...</td>\n",
       "      <td>2001-07-04</td>\n",
       "      <td>Madani, Tariq A; Al-Ghamdi, Aisha A</td>\n",
       "      <td>BMC Infect Dis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/d1aafb70c066a2068b027...</td>\n",
       "      <td>document_parses/pmc_json/PMC35282.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02tnwd4m</td>\n",
       "      <td>6b0567729c2143a66d737eb0a2f63f2dce2e5a7d</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n",
       "      <td>10.1186/rr14</td>\n",
       "      <td>PMC59543</td>\n",
       "      <td>11667967</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Inflammatory diseases of the respiratory tract...</td>\n",
       "      <td>2000-08-15</td>\n",
       "      <td>Vliet, Albert van der; Eiserich, Jason P; Cros...</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/6b0567729c2143a66d737...</td>\n",
       "      <td>document_parses/pmc_json/PMC59543.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ejv2xln0</td>\n",
       "      <td>06ced00a5fc04215949aa72528f2eeaae1d58927</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Surfactant protein-D and pulmonary host defense</td>\n",
       "      <td>10.1186/rr19</td>\n",
       "      <td>PMC59549</td>\n",
       "      <td>11667972</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Surfactant protein-D (SP-D) participates in th...</td>\n",
       "      <td>2000-08-25</td>\n",
       "      <td>Crouch, Erika C</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/06ced00a5fc04215949aa...</td>\n",
       "      <td>document_parses/pmc_json/PMC59549.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cord_uid                                       sha source_x  \\\n",
       "0  ug7v899j  d1aafb70c066a2068b02786f8929fd9c900897fb      PMC   \n",
       "1  02tnwd4m  6b0567729c2143a66d737eb0a2f63f2dce2e5a7d      PMC   \n",
       "2  ejv2xln0  06ced00a5fc04215949aa72528f2eeaae1d58927      PMC   \n",
       "\n",
       "                                               title                    doi  \\\n",
       "0  Clinical features of culture-proven Mycoplasma...  10.1186/1471-2334-1-6   \n",
       "1  Nitric oxide: a pro-inflammatory mediator in l...           10.1186/rr14   \n",
       "2    Surfactant protein-D and pulmonary host defense           10.1186/rr19   \n",
       "\n",
       "      pmcid pubmed_id license  \\\n",
       "0  PMC35282  11472636   no-cc   \n",
       "1  PMC59543  11667967   no-cc   \n",
       "2  PMC59549  11667972   no-cc   \n",
       "\n",
       "                                            abstract publish_time  \\\n",
       "0  OBJECTIVE: This retrospective chart review des...   2001-07-04   \n",
       "1  Inflammatory diseases of the respiratory tract...   2000-08-15   \n",
       "2  Surfactant protein-D (SP-D) participates in th...   2000-08-25   \n",
       "\n",
       "                                             authors         journal  mag_id  \\\n",
       "0                Madani, Tariq A; Al-Ghamdi, Aisha A  BMC Infect Dis     NaN   \n",
       "1  Vliet, Albert van der; Eiserich, Jason P; Cros...      Respir Res     NaN   \n",
       "2                                    Crouch, Erika C      Respir Res     NaN   \n",
       "\n",
       "  who_covidence_id arxiv_id  \\\n",
       "0              NaN      NaN   \n",
       "1              NaN      NaN   \n",
       "2              NaN      NaN   \n",
       "\n",
       "                                      pdf_json_files  \\\n",
       "0  document_parses/pdf_json/d1aafb70c066a2068b027...   \n",
       "1  document_parses/pdf_json/6b0567729c2143a66d737...   \n",
       "2  document_parses/pdf_json/06ced00a5fc04215949aa...   \n",
       "\n",
       "                               pmc_json_files  \\\n",
       "0  document_parses/pmc_json/PMC35282.xml.json   \n",
       "1  document_parses/pmc_json/PMC59543.xml.json   \n",
       "2  document_parses/pmc_json/PMC59549.xml.json   \n",
       "\n",
       "                                                 url  s2_id  \n",
       "0  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...    NaN  \n",
       "1  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  \n",
       "2  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "f_metadata_path = \"./archive/metadata.csv\"\n",
    "\n",
    "# construct the data frame of metadata\n",
    "df = pd.read_csv(f_metadata_path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7e5bbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1056660, 19)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d2b1b19",
   "metadata": {},
   "source": [
    "#### 1.2 Dropping useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6307cc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>pdf_json_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ug7v899j</td>\n",
       "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
       "      <td>OBJECTIVE: This retrospective chart review des...</td>\n",
       "      <td>2001-07-04</td>\n",
       "      <td>document_parses/pdf_json/d1aafb70c066a2068b027...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cord_uid                                              title  \\\n",
       "0  ug7v899j  Clinical features of culture-proven Mycoplasma...   \n",
       "\n",
       "                                            abstract publish_time  \\\n",
       "0  OBJECTIVE: This retrospective chart review des...   2001-07-04   \n",
       "\n",
       "                                      pdf_json_files  \n",
       "0  document_parses/pdf_json/d1aafb70c066a2068b027...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop useless columns for this assignment\n",
    "df_trimed = df.drop([\"sha\", \"source_x\", \"doi\", \"license\", \"authors\", \"journal\", \"pmc_json_files\",\n",
    "                    \"pmcid\", \"pubmed_id\", \"mag_id\", \"who_covidence_id\", \"arxiv_id\", \"url\", \"s2_id\"], axis=1)\n",
    "df_trimed.head(1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46830d8d",
   "metadata": {},
   "source": [
    "#### 1.3 Sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e71cbf1",
   "metadata": {},
   "source": [
    "Given that COVID-19 was first reported in December 2019, we can limit our data selection to articles published after this date. Therefore, we will sample data from December 1st, 2019, onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0950807e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "958037"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep the documents published after 2019-11\n",
    "df_trimed = df_trimed[df_trimed[\"publish_time\"] > '2019-12']\n",
    "df_trimed.shape[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2c85fbe",
   "metadata": {},
   "source": [
    "Check the missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "547731b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cord_uid               0\n",
       "title                488\n",
       "abstract          220150\n",
       "publish_time           0\n",
       "pdf_json_files    628520\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of missing value in each column\n",
    "missing_values_count = df_trimed.isnull().sum()\n",
    "missing_values_count\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "317185ec",
   "metadata": {},
   "source": [
    "Many rows of data have missing titles, abstracts, and PDF files, as demonstrated above. We will drop these rows from our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81623f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287065"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trimed = df_trimed.dropna(subset=['pdf_json_files', 'title', 'abstract'])\n",
    "df_trimed.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "464a2893",
   "metadata": {},
   "source": [
    "Next, we will verify the validity of the PDF file URLs. Any rows with invalid URLs will be dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73b074a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "removing all the rows that do not have the real file...: 100%|██████████| 287065/287065 [00:56<00:00, 5072.17it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "267675"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all the rows that do not have the real file\n",
    "# tqdm progress apply\n",
    "tqdm.pandas(desc=\"removing all the rows that do not have the real file...\")\n",
    "df_trimed = df_trimed[df_trimed['pdf_json_files'].progress_apply(\n",
    "    lambda x: os.path.isfile(\"./archive/\"+x))]\n",
    "df_trimed.shape[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f2d5f75",
   "metadata": {},
   "source": [
    "Based on the keywords of the test queries, we can sample the data further. We will only keep the rows whose title or abstract contain the keywords in the test queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a86b2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: select the rows whose title or abstract contain the given strings, ignoring the case\n",
    "def select_rows_contain_string(df, strings):\n",
    "    tqdm.pandas(\n",
    "        desc=\"selecting the rows whose title or abstract contain the given strings...\")\n",
    "    return df[df.progress_apply(lambda row: any(string in row['title'].lower() or string in row['abstract'].lower() for string in strings), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5aef8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "selecting the rows whose title or abstract contain the given strings...: 100%|██████████| 267675/267675 [00:14<00:00, 18940.84it/s]\n",
      "selecting the rows whose title or abstract contain the given strings...: 100%|██████████| 158540/158540 [00:03<00:00, 40936.46it/s]\n",
      "selecting the rows whose title or abstract contain the given strings...: 100%|██████████| 158540/158540 [00:02<00:00, 64529.63it/s]\n",
      "selecting the rows whose title or abstract contain the given strings...: 100%|██████████| 158540/158540 [00:04<00:00, 32059.81it/s]\n",
      "selecting the rows whose title or abstract contain the given strings...: 100%|██████████| 158540/158540 [00:02<00:00, 65275.43it/s]\n",
      "selecting the rows whose title or abstract contain the given strings...: 100%|██████████| 158540/158540 [00:10<00:00, 14715.14it/s]\n",
      "selecting the rows whose title or abstract contain the given strings...: 100%|██████████| 158540/158540 [00:02<00:00, 58777.23it/s]\n",
      "selecting the rows whose title or abstract contain the given strings...: 100%|██████████| 158540/158540 [00:06<00:00, 24244.63it/s]\n",
      "selecting the rows whose title or abstract contain the given strings...: 100%|██████████| 158540/158540 [00:02<00:00, 63804.44it/s]\n",
      "selecting the rows whose title or abstract contain the given strings...: 100%|██████████| 158540/158540 [00:02<00:00, 65114.48it/s]\n",
      "selecting the rows whose title or abstract contain the given strings...: 100%|██████████| 158540/158540 [00:02<00:00, 61273.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# title or abstract contain \"COVID-19\", \"SARS-CoV-2\", \"coronavirus\", \"2019-nCoV\", \"covid\", \"covid-19\", \"Covid-19\"\n",
    "strings = [\"COVID-19\", \"SARS-CoV-2\", \"coronavirus\",\n",
    "           \"2019-nCoV\", \"covid\", \"covid-19\", \"Covid-19\"]\n",
    "df_trimed_covid = select_rows_contain_string(df_trimed, strings)\n",
    "\n",
    "keyword_sampled_df_list = []\n",
    "\n",
    "# title or abstract contain \"origin\", \"Wuhan\" from the df_trimed_covid\n",
    "strings = [\"origin\", \"Wuhan\"]\n",
    "df_trimed_origin = select_rows_contain_string(df_trimed_covid, strings)\n",
    "keyword_sampled_df_list.append(df_trimed_origin)\n",
    "\n",
    "# title or abstract contain \"rapid testing\"\n",
    "strings = [\"rapid testing\"]\n",
    "df_trimed_testing = select_rows_contain_string(df_trimed_covid, strings)\n",
    "keyword_sampled_df_list.append(df_trimed_testing)\n",
    "\n",
    "# title or abstract contain \"social\", \"distancing\", \"lockdown\", \"quarantine\"\n",
    "strings = [\"social distancing\", \"lockdown\", \"quarantine\"]\n",
    "df_trimed_social = select_rows_contain_string(df_trimed_covid, strings)\n",
    "keyword_sampled_df_list.append(df_trimed_social)\n",
    "\n",
    "# title or abstract contain \"transmission route\"\n",
    "strings = [\"transmission route\"]\n",
    "df_trimed_transmission = select_rows_contain_string(df_trimed_covid, strings)\n",
    "keyword_sampled_df_list.append(df_trimed_transmission)\n",
    "\n",
    "# title or abstract contain \"best masks\", \"preventing infection\", \"prevent infection\", \"preventing transmission\", \"prevent transmission\", \"preventing spread\", \"prevent spread\"\n",
    "strings = [\"best masks\", \"preventing infection\", \"prevent infection\",\n",
    "           \"preventing transmission\", \"prevent transmission\", \"preventing spread\", \"prevent spread\"]\n",
    "df_trimed_masks = select_rows_contain_string(df_trimed_covid, strings)\n",
    "keyword_sampled_df_list.append(df_trimed_masks)\n",
    "\n",
    "# title or abstract contain \"hand sanitizer\"\n",
    "strings = [\"hand sanitizer\"]\n",
    "df_trimed_sanitizer = select_rows_contain_string(df_trimed_covid, strings)\n",
    "keyword_sampled_df_list.append(df_trimed_sanitizer)\n",
    "\n",
    "# title or abstract contain \"vaccine\", \"vaccination\", \"vaccines\", \"vaccinations\"\n",
    "strings = [\"vaccine\", \"vaccination\", \"vaccines\", \"vaccinations\"]\n",
    "df_trimed_vaccine = select_rows_contain_string(df_trimed_covid, strings)\n",
    "keyword_sampled_df_list.append(df_trimed_vaccine)\n",
    "\n",
    "# title or abstract contain \"Vitamin\"\n",
    "strings = [\"Vitamin\"]\n",
    "df_trimed_vitamin = select_rows_contain_string(df_trimed_covid, strings)\n",
    "keyword_sampled_df_list.append(df_trimed_vitamin)\n",
    "\n",
    "# title or abstract contain \"live outside the body\"\n",
    "strings = [\"live outside the body\"]\n",
    "df_trimed_outside = select_rows_contain_string(df_trimed_covid, strings)\n",
    "keyword_sampled_df_list.append(df_trimed_outside)\n",
    "\n",
    "# title or abstract contain \"initial symptoms\"\n",
    "strings = [\"initial symptoms\"]\n",
    "df_trimed_symptoms = select_rows_contain_string(df_trimed_covid, strings)\n",
    "keyword_sampled_df_list.append(df_trimed_symptoms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a8a073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43311"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join all the dataframes above into one dataframe and remove the duplicates\n",
    "df_trimed_covid = pd.concat(keyword_sampled_df_list).drop_duplicates()\n",
    "df_trimed_covid.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "486277c9",
   "metadata": {},
   "source": [
    "Finally, we randomly sample 10000 rows from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15565e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly pick 10000 documents from the dataset\n",
    "# df_sampled = df_trimed_covid.sample(n=10000, random_state=42)\n",
    "df_sampled = df_trimed_covid.sample(n=10000, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "716862f0",
   "metadata": {},
   "source": [
    "#### 1.4 Pre-processing the text data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "243e3b4d",
   "metadata": {},
   "source": [
    "After sampling the data, our next step is to pre-process the text data. This involves extracting the text from the PDF JSON files as our first task. And then, we will put all the paragraphs of the corpus into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95fad4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0ex7dy6g_0</th>\n",
       "      <td>The COVID‐19 pandemic and the associated infec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0ex7dy6g_1</th>\n",
       "      <td>A severe acute respiratory syndrome, coronavir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0ex7dy6g_2</th>\n",
       "      <td>Typically, national/governmental IPC initiativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0ex7dy6g_3</th>\n",
       "      <td>MB designed the study, collected, and analysed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0ex7dy6g_4</th>\n",
       "      <td>All procedures involved in this study were in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7cwve06g_22</th>\n",
       "      <td>This study has some limitations. First, the su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7cwve06g_23</th>\n",
       "      <td>Our survey revealed that 89% of the 1,499 Chin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7cwve06g_24</th>\n",
       "      <td>The original contributions presented in the st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7cwve06g_25</th>\n",
       "      <td>NZ, HL, JX, and YL conceived the study. NZ, LL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7cwve06g_26</th>\n",
       "      <td>This study was supported by the Natural Scienc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350671 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          text\n",
       "p_id                                                          \n",
       "0ex7dy6g_0   The COVID‐19 pandemic and the associated infec...\n",
       "0ex7dy6g_1   A severe acute respiratory syndrome, coronavir...\n",
       "0ex7dy6g_2   Typically, national/governmental IPC initiativ...\n",
       "0ex7dy6g_3   MB designed the study, collected, and analysed...\n",
       "0ex7dy6g_4   All procedures involved in this study were in ...\n",
       "...                                                        ...\n",
       "7cwve06g_22  This study has some limitations. First, the su...\n",
       "7cwve06g_23  Our survey revealed that 89% of the 1,499 Chin...\n",
       "7cwve06g_24  The original contributions presented in the st...\n",
       "7cwve06g_25  NZ, HL, JX, and YL conceived the study. NZ, LL...\n",
       "7cwve06g_26  This study was supported by the Natural Scienc...\n",
       "\n",
       "[350671 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the list of paragraphs\n",
    "paragraphs = []\n",
    "for index, row in df_sampled.iterrows():\n",
    "    paragraph_obj = {}\n",
    "    paragraph_obj['text'] = row['abstract']\n",
    "    paragraph_obj['p_id'] = row['cord_uid'] + \"_0\"\n",
    "    paragraphs.append(paragraph_obj)\n",
    "    # extract the paragraphs from the json file\n",
    "    with open(\"./archive/\"+row['pdf_json_files']) as f:\n",
    "        json_data = json.load(f)\n",
    "        p_index = 1\n",
    "        for body in json_data['body_text']:\n",
    "            paragraph_obj = {}\n",
    "            paragraph_obj['text'] = body['text']\n",
    "            paragraph_obj['p_id'] = row['cord_uid'] + \"_\" + str(p_index)\n",
    "            paragraphs.append(paragraph_obj)\n",
    "            p_index += 1\n",
    "\n",
    "# turn the list of paragraphs into a dataframe\n",
    "df_paragraphs = pd.DataFrame(paragraphs)\n",
    "# set the index of the dataframe to be the p_id\n",
    "df_paragraphs = df_paragraphs.set_index('p_id')\n",
    "df_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf958511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "selecting the rows whose title or abstract contain the given strings...: 100%|██████████| 350671/350671 [00:00<00:00, 1117915.10it/s]\n",
      "selecting the rows whose title or abstract contain the given strings...: 100%|██████████| 350671/350671 [00:00<00:00, 1141517.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# drop the paragraphs that are not text\n",
    "df_paragraphs = df_paragraphs[df_paragraphs['text'].progress_apply(lambda x: type(x) == str)]\n",
    "\n",
    "# drop the paragraphs what are shorter than 50 characters\n",
    "df_paragraphs = df_paragraphs[df_paragraphs['text'].progress_apply(lambda x: len(x) > 50)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e63f9bd2",
   "metadata": {},
   "source": [
    "Next, we can preprocess each paragraph in the paragraph list for the following word embedding. Preprocessing the text involves several tasks: first, we will convert all text to lowercase and remove stopwords. Next, we will perform lemmatization and store the preprocessed text in a separate column for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80692379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessing the text in the paragraphs...: 100%|██████████| 340517/340517 [04:06<00:00, 1380.45it/s]\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# function that preprocesses the input string\n",
    "def preprocess_text(string):\n",
    "    string = string.lower()\n",
    "    # remove stopwords\n",
    "    string = \" \".join([word for word in string.split()\n",
    "                      if word not in stop_words])\n",
    "    # lemmatization\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    string = \" \".join([lemmatizer.lemmatize(word) for word in string.split()])\n",
    "    return string\n",
    "\n",
    "# function that preprocesses the text of a row in the paragraphs dataset\n",
    "def preprocess_text_in_df_paragraphs(row):\n",
    "    row[\"preprocessed_text\"] = preprocess_text(row['text'])\n",
    "    return row\n",
    "\n",
    "tqdm.pandas(desc=\"preprocessing the text in the paragraphs...\")\n",
    "df_paragraphs = df_paragraphs.progress_apply(\n",
    "    lambda row: preprocess_text_in_df_paragraphs(row), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13bdbc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0ex7dy6g_0</th>\n",
       "      <td>The COVID‐19 pandemic and the associated infec...</td>\n",
       "      <td>covid‐19 pandemic associated infection prevent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0ex7dy6g_1</th>\n",
       "      <td>A severe acute respiratory syndrome, coronavir...</td>\n",
       "      <td>severe acute respiratory syndrome, coronavirus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0ex7dy6g_2</th>\n",
       "      <td>Typically, national/governmental IPC initiativ...</td>\n",
       "      <td>typically, national/governmental ipc initiativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0ex7dy6g_3</th>\n",
       "      <td>MB designed the study, collected, and analysed...</td>\n",
       "      <td>mb designed study, collected, analysed data, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0ex7dy6g_4</th>\n",
       "      <td>All procedures involved in this study were in ...</td>\n",
       "      <td>procedure involved study accordance ethical st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text  \\\n",
       "p_id                                                            \n",
       "0ex7dy6g_0  The COVID‐19 pandemic and the associated infec...   \n",
       "0ex7dy6g_1  A severe acute respiratory syndrome, coronavir...   \n",
       "0ex7dy6g_2  Typically, national/governmental IPC initiativ...   \n",
       "0ex7dy6g_3  MB designed the study, collected, and analysed...   \n",
       "0ex7dy6g_4  All procedures involved in this study were in ...   \n",
       "\n",
       "                                            preprocessed_text  \n",
       "p_id                                                           \n",
       "0ex7dy6g_0  covid‐19 pandemic associated infection prevent...  \n",
       "0ex7dy6g_1  severe acute respiratory syndrome, coronavirus...  \n",
       "0ex7dy6g_2  typically, national/governmental ipc initiativ...  \n",
       "0ex7dy6g_3  mb designed study, collected, analysed data, w...  \n",
       "0ex7dy6g_4  procedure involved study accordance ethical st...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paragraphs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6373cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paragraphs.to_csv(\"paragraphs_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d75afc",
   "metadata": {},
   "source": [
    "### 2. Named Entity Recognition and Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39fbb3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the df_sampled dataframe and the paragraphs dataframe\n",
    "df_paragraphs = pd.read_csv(\"paragraphs_preprocessed.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb332553",
   "metadata": {},
   "source": [
    "#### 2.1 Entity extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f184ff5",
   "metadata": {},
   "source": [
    "To save time, we will only extract entities from the title and abstract sections of the text. These sections of the article are most likely to contain entities that are relevant to the topic of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f21a1131",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# function: get the name entities from the title, abstract, introduction, and conclusion of each data in the dataset\n",
    "def get_name_entity(row):\n",
    "    name_entity = []\n",
    "    doc = nlp(row[\"title\"])\n",
    "    for ent in doc.ents:\n",
    "        # if ent is not number\n",
    "        if ent.label_ != \"CARDINAL\" and ent.label_ != \"PERCENT\" and ent.label_ != \"MONEY\":\n",
    "            name_entity.append(ent.text)\n",
    "    doc = nlp(row[\"abstract\"])\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ != \"CARDINAL\" and ent.label_ != \"PERCENT\" and ent.label_ != \"MONEY\":\n",
    "            name_entity.append(ent.text)\n",
    "    return name_entity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10bd5cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting name entity...: 100%|██████████| 10000/10000 [06:27<00:00, 25.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# get the name entity of the title, abstract, introduction, and conclusion of each data in the dataset\n",
    "tqdm.pandas(desc=\"Getting name entity...\")\n",
    "df_sampled['name_entity'] = df_sampled.progress_apply(\n",
    "    lambda row: get_name_entity(row), axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5da1b198",
   "metadata": {},
   "source": [
    "Presenting the frequency of the extracted entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1d967ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('COVID-19', 26011),\n",
       " ('first', 2644),\n",
       " ('2019', 2381),\n",
       " ('CI', 1797),\n",
       " ('COVID‐19', 1511),\n",
       " ('China', 1378),\n",
       " ('second', 1330),\n",
       " ('2020', 924),\n",
       " ('India', 846),\n",
       " ('daily', 666)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the name entity into one list\n",
    "name_entity_list = []\n",
    "for name_entity in df_sampled['name_entity']:\n",
    "    name_entity_list.extend(name_entity)\n",
    "\n",
    "# count the frequency of each name entity and sort it\n",
    "name_entity_count = Counter(name_entity_list)\n",
    "name_entity_count = sorted(name_entity_count.items(),\n",
    "                           key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# show the top 10 name entity\n",
    "name_entity_count[:10]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "524cc54e",
   "metadata": {},
   "source": [
    "#### 2.2 Knowledge base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52e5c501",
   "metadata": {},
   "source": [
    "We will manually build knowledge bases that display synonyms of the entities and their associated keywords. This will be based on the results of the Named Entity Recognition and the test query set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8ea1cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually create the knowledge base\n",
    "\n",
    "# create the knowledge base\n",
    "knowledge_base_synonym = {\n",
    "    \"COVID-19\": [\"SARS-CoV-2\", \"coronavirus disease 2019\", \"2019-nCoV\"],\n",
    "    \"rapid testing\": [\"RAT\", \"rapid test\", \"rapid antigen test\", \"rapid antigen tests\", \"rapid antigen testing\", \"rapid antigen tests\", \"rapid antigen test kit\"],\n",
    "    \"origin\": [\"origins\", \"source\", \"sources\"],\n",
    "    \"initial symtoms\": [\"early signs\"]\n",
    "}\n",
    "\n",
    "knowledge_base_association = {\n",
    "    \"mask\": [\"n95\", \"cloth mask\"],\n",
    "    \"vaccine\": [\"mrna\"],\n",
    "    \"origin\": [\"wuhan\", \"fish market\"],\n",
    "    \"symptoms\": [\"fever\", \"chill\", \"cough\", \"tired\", \"headache\", \"loss taste or small\", \"sore throat\", \"diarrhea\"],\n",
    "    \"sanitizer\": [\"alcohol\"],\n",
    "    \"social distancing\": [\"quarantine\", \"lockdown\"],\n",
    "    \"transmission route\": [\"airborne\", \"droplet\", \"contact\", \"fomite\"],\n",
    "    \"testing\": [\"PCR\"], \n",
    "    \"mental health\": [\"depression\", \"anxiety\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333cefa8",
   "metadata": {},
   "source": [
    "### 3. Indexing method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dddddc44",
   "metadata": {},
   "source": [
    "To efficiently retrieve paragraphs containing words from the query, we will utilize the inverted index method. This method creates a dictionary that maps words to the paragraphs that contain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4209d4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting unique words...: 100%|██████████| 340517/340517 [00:29<00:00, 11411.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# the unique word set of the preprocessed_text of the dataset\n",
    "unique_word_set = set([])\n",
    "\n",
    "def get_unique_words(row):\n",
    "    for word in row['preprocessed_text'].split():\n",
    "        # if not a single puctuation\n",
    "        if re.match(r'^[^\\w\\s]$', word) == None:\n",
    "            unique_word_set.add(word)\n",
    "\n",
    "\n",
    "tqdm.pandas(desc=\"Getting unique words...\")\n",
    "result = df_paragraphs.progress_apply(lambda row: get_unique_words(row), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78373198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting inverted index...: 100%|██████████| 340517/340517 [01:16<00:00, 4447.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# the inverted index of the preprocessed_text of the dataset\n",
    "inverted_index = inv_indx = {i: [] for i in unique_word_set}\n",
    "\n",
    "# function: get the inverted index of the preprocessed_text of the dataset\n",
    "def get_inverted_index(row, inverted_index):\n",
    "    for word in row['preprocessed_text'].split():\n",
    "        if word in inverted_index:\n",
    "            inverted_index[word].append(row['p_id'])\n",
    "\n",
    "\n",
    "tqdm.pandas(desc=\"Getting inverted index...\")\n",
    "result = df_paragraphs.progress_apply(\n",
    "    lambda row: get_inverted_index(row, inverted_index), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "208fc830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pyxmblll_8', 'pyxmblll_13', 'ilq5xaey_10', 'n9ytx2pa_11', '8e8evwn4_4']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstration: get the paragraphs containing the word \"covid\"\n",
    "inverted_index[\"covid\"][:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "067cebcf",
   "metadata": {},
   "source": [
    "### 4. Relevant paragraphs retrieval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc4a548a",
   "metadata": {},
   "source": [
    "#### 4.1 Word embedding based "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb80e320",
   "metadata": {},
   "source": [
    "The first method of retrieval is based on the method we used in the Assignment 2, which is using word embedding and cosine similarity. We will first extend the query by adding related entities from the knowledge base. Next, we will use the inverted index method to filter paragraphs containing the words from the extended query. We will then calculate cosine similarity between the query vector and the paragraph vector to rank them and select the top 3 paragraphs as the relevant paragraphs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c54d264",
   "metadata": {},
   "source": [
    "First, we define the function to preprocess the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7e9da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: extend the query with the knowledge base\n",
    "def extend_query(query, knowledge_base_synonym, knowledge_base_association):\n",
    "    # convert the query to lower case\n",
    "    query = query.lower()\n",
    "    # for each key in the knowledge base, if the key is in the query, then add the value to the query string\n",
    "    for key in knowledge_base_synonym:\n",
    "        # if the query string contains the key\n",
    "        if key.lower() in query:\n",
    "            # concatenate the query string with each value of the key\n",
    "            for value in knowledge_base_synonym[key]:\n",
    "                query += \" \" + value\n",
    "    for key in knowledge_base_association:\n",
    "        if key.lower() in query:\n",
    "            for value in knowledge_base_association[key]:\n",
    "                query += \" \" + value\n",
    "    return query\n",
    "\n",
    "# query preprocessing: extend the query with the knowledge base, remove stopwords, lemmatization, and remove question mark\n",
    "def preprocess_query(query):\n",
    "    # extend the query with the knowledge base\n",
    "    query = extend_query(query, knowledge_base_synonym,\n",
    "                         knowledge_base_association)\n",
    "    query = query.lower()\n",
    "    # remove stopwords\n",
    "    query = \" \".join([word for word in query.split()\n",
    "                     if word not in stop_words])\n",
    "    # lemmatization\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    query = \" \".join([lemmatizer.lemmatize(word) for word in query.split()])\n",
    "    # remove question mark\n",
    "    query = query.replace(\"?\", \"\")\n",
    "    return query\n",
    "\n",
    "# function: get the paragraph id of the paragraphs that contain the query\n",
    "def get_paragraph_id(query, inverted_index):\n",
    "    # define the paragraph id set\n",
    "    paragraph_id_set = set([])\n",
    "    # for each word in the query\n",
    "    for word in query.split():\n",
    "        # if the word is in the inverted index\n",
    "        if word in inverted_index:\n",
    "            # add the paragraph id to the paragraph id set\n",
    "            paragraph_id_set.update(inverted_index[word])\n",
    "    return paragraph_id_set\n",
    "\n",
    "# function: get the vector representation of the query by averaging the vector representation of each word in the query\n",
    "def embedding_string(string):\n",
    "    vectors = []\n",
    "    for word in string.split():\n",
    "        if word in glove_model:\n",
    "            vectors.append(glove_model[word])\n",
    "    if vectors == []:\n",
    "        return np.zeros(100)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# function: calculate the cosine similarity between two vectors\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    return np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a2ce578",
   "metadata": {},
   "source": [
    "Then we can get the embedding of each paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57913daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting embedding for all paragraphs...: 100%|██████████| 340517/340517 [01:01<00:00, 5531.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [-0.0042234645, 0.21141529, 0.26677096, 0.1978...\n",
       "1    [-0.040232472, 0.1667354, 0.16827837, 0.267589...\n",
       "2    [-0.07398014, 0.13700563, 0.047724877, -0.0032...\n",
       "3    [-0.27477884, 0.23193273, 0.087432, -0.1762163...\n",
       "4    [0.021956295, 0.05252984, -0.027892865, 0.1695...\n",
       "Name: embedding, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the vector representation of each paragraph\n",
    "tqdm.pandas(desc=\"Getting embedding for all paragraphs...\")\n",
    "df_paragraphs['embedding'] = df_paragraphs.progress_apply(\n",
    "    lambda row: embedding_string(row['preprocessed_text']), axis=1)\n",
    "\n",
    "df_paragraphs['embedding'][:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31f0ea01",
   "metadata": {},
   "source": [
    "Now we can use the above functions to get the relevant paragraphs using the word embedding method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "837170f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: get the top n paragraphs that are most similar to the query from the paragraphs dataframe, using word embedding\n",
    "def get_top_n_paragraphs_wb(query_string, df_paragraphs, inverted_index,  n):\n",
    "    # embad the query\n",
    "    query_vector = embedding_string(query_string)\n",
    "    # get the paragraph id of the paragraphs that contain the query\n",
    "    indexed_paragraph_id_set = get_paragraph_id(query_string, inverted_index)\n",
    "    # filter the paragraphs dataframe by the paragraph id set\n",
    "    indexed_df_paragraphs = df_paragraphs[df_paragraphs['p_id'].isin(\n",
    "        indexed_paragraph_id_set)]\n",
    "    # calculate the cosine similarity between the query and each paragraph\n",
    "    indexed_df_paragraphs['similarity'] = indexed_df_paragraphs.apply(\n",
    "        lambda row: cosine_similarity(query_vector, row['embedding']), axis=1)\n",
    "    # sort the paragraphs by the similarity score\n",
    "    indexed_df_paragraphs = indexed_df_paragraphs.sort_values(by=['similarity'], ascending=False)\n",
    "    # get the top n paragraphs\n",
    "    df_top_n = indexed_df_paragraphs[:n]\n",
    "    return df_top_n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f064060",
   "metadata": {},
   "source": [
    "Now we can find the top 3 paragraphs for the question \"what are the symptoms of covid-19\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8aa67398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regarding COVID-19, the research shows that 6.9% of participants had symptoms related to this. However, many of the COVID-19 symptoms such as the flu, cough, fever, and tiredness are already part of the health issues experienced by those living on the streets. As a result of this, they may have gone unnoticed as something different from the usual for many people living in these conditions.\n",
      "\n",
      "Six months and several thousand papers and preprints after the beginning of the pandemic, if there is one thing we have learnt about SARS-CoV-2, it is that almost every assumption that has been made about the virus has been wrong. Although viral pneumonia, complicated by the \"cytokine storm\" and a prothrombotic state (28-31), is still the principal symptom in severely ill patients, other tissues, notably the gut, are also directly susceptible to infection (32). While our study may seem at first sight to resemble the parable of the blind men and the elephant, we consider the possibility that SARS-CoV-2 infiltrates the brain, and specifically the hypothalamus, with functional consequences to disease progression and outcome, to be more in the nature of the elephant in the room. Our current observations of SARS-CoV-2 S-and N-proteins as well as dsRNA in cells of the hypothalamic ME lay to rest any doubt in this regard.\n",
      "\n",
      "Comparing and contrasting SARS-CoV-2 with the other six HCoVs reveal similarities and differences of great interest. First, the incubation period and the duration of the course of HCoV disease are very similar. In this regard, SARS-CoV-2 follows the general trend of the other six HCoVs. Second, the severity of symptoms of COVID-19 lies between SARS-CoV and the four community-acquired HCoVs (i.e. HCoV-229E, HCoV-OC43, HCoV-HKU1 and HCoV-NL63). On one hand, SARS-CoV-2 infection exhibits features that are more commonly seen during infection with community-acquired HCoVs, including the presentation of non-specific, mild or even no symptoms. On the other hand, a small subset of severe cases of COVID-19 can also be seen as in the case of SARS-CoV infection, although the ratio is a bit lower. Third, the transmission of SARS-CoV-2 also shows interesting patterns characteristic of both community-acquired HCoVs and SARS-CoV. On one hand, the transmissibility of SARS-CoV-2 is at least as high as that of community-acquired HCoVs. On the other hand, it remains to be verified whether the transmissibility of SARS-CoV-2 decreases after passages in humans as in the cases of SARS-CoV and MERS-CoV. Finally, same as the other HCoVs [41] , SARS-CoV-2 can be detected in fecal samples. Whether fecal-oral transmission of SARS-CoV-2 plays an important role as in the case of SARS-CoV at least under some circumstance remains to be clarified by future studies. It is also of particularly great interest to see whether SARS-CoV-2 might exhibit seasonality as in the cases of community-acquired HCoVs. Nevertheless, the features of SARS-CoV-2 including its transmissibility, pathogenicity and sustainable spreading after passages in humans will be influential on the ultimate fate of the ongoing outbreak of COVID-19.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_3_paragraph_wb = get_top_n_paragraphs_wb(\"what are the symptom of covid-19\", df_paragraphs, inverted_index, 3)\n",
    "\n",
    "for index, row in top_3_paragraph_wb.iterrows():\n",
    "    print(row['text'])\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19de8110",
   "metadata": {},
   "source": [
    "#### 4.2 Text matching utility based on the pyserini library (Harsh's code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5efb3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the paragraphs dataframe to json format that can be used by pyserini\n",
    "convert_json_list = []\n",
    "def convert_to_json(row):\n",
    "    convert_json_list.append({\n",
    "        \"id\": row[\"p_id\"],\n",
    "        \"contents\": row[\"text\"]\n",
    "    })\n",
    "\n",
    "x = df_paragraphs.apply(lambda row: convert_to_json(row), axis=1)\n",
    "\n",
    "json_str = json.dumps(convert_json_list)\n",
    "with open(\"collection/collection.json\", \"w\") as outfile:\n",
    "    outfile.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d57f9a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# use pyserini to index the json file\n",
    "!python -m pyserini.index.lucene \\\n",
    "  --collection JsonCollection \\\n",
    "  --input ./collection \\\n",
    "  --index index \\\n",
    "  --generator DefaultLuceneDocumentGenerator \\\n",
    "  --threads 4 \\\n",
    "  --storePositions --storeDocvectors --storeRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "900f5cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Respondents were asked what they believed their risk of getting COVID-19 was in the next month, 3 months, and 6 months. Responses were rated on scale from 0 to 100%. COVID-19 symptom severity: Respondents were asked if they were to get COVID-19 what severity of symptoms they believed they would experience. This was rated on 5point Likert scale ranging from asymptomatic/no symptoms (1) to deadly symptoms (5). COVID-19 exposure: Respondents were asked whether, at the time of completing the survey, they knew someone who was currently or in the past had been diagnosed with COVID-19. This variable was coded as yes (1), no (0). Responses of 'don't know' were recoded and treated as missing data. COVID-19 media consumption: Frequency of watching, reading, and hearing reports or updates about COVID-19 on social media (e.g., Twitter, Facebook, and WhatsApp) and on traditional media (e.g., TV, radio, and newspaper) over the past month were assessed. Responses were dichotomized to indicate 'low exposure' (1; 0 -5 times a day) and 'high exposure' (2; 6 or more times a day).\",\n",
       " 'Personal experience about COVID-19-A questionnaire to investigate the personal experience about COVID-19 disease was designed. It was composed of five items to evaluate the experience of COVID-19 infection by participants and their relatives and the perceived probability of contracting it soon (i.e., \"Were you sick with COVID-19?\" (yes/no); \"What was the severity of the symptoms?\" (mild/moderate/severe but manageable at home/hospitalization); \"How likely do you think a COVID-19 infection will be in the next few months?\" (not at all/slightly probable/quite probable/very probable/at all); \"Did one or more of your relatives or people close to you fall ill with COVID-19?\" (yes/no); \"What was the severity of the symptoms?\" (mild/moderate/severe but manageable at home/hospitalization/death)). Attitude towards COVID-19 vaccine-Two questions to delve into the attitude towards COVID-19 vaccine were designed (\"Regardless of whether you have already been vaccinated against the COVID-19, what is your attitude towards the COVID-19 vaccine?\" (extremely contrary/contrary/neither contrary nor favorable/favorable/entirely favorable); \"If you think about your attitude towards the vaccine for COVID-19 before the start of the vaccination campaign, has it changed?\" (much less favorable/slightly less favorable/unchanged/slightly more favorable/much more favorable)). Answers were rated on a 5-point Likert scale.',\n",
       " 'The main questions of the study included the following. What is the mortality rate of COVID-19 in pregnant and postpartum women, and how many and what type of comorbidities were found in recovered and deceased patients? What were the disease symptoms and the mode of delivery in the maternal deaths?']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_n_paragraphs_pyserini(query, n):\n",
    "    searcher = LuceneSearcher('./index')\n",
    "\n",
    "    hits = searcher.search(query)\n",
    "\n",
    "    top_n_paragraphs = []\n",
    "\n",
    "    for i in range(0, n):\n",
    "        top_n_paragraphs.append(json.loads(hits[i].raw))\n",
    "    # turn the top_n_paragraphs list into a dataframe\n",
    "    df_top_n_paragraphs = pd.DataFrame(top_n_paragraphs)\n",
    "\n",
    "    # turn the contents column into a list\n",
    "    paragraph_list = df_top_n_paragraphs[\"contents\"].tolist()\n",
    "    return paragraph_list\n",
    "\n",
    "top_3_paragraphs_pyserini = get_top_n_paragraphs_pyserini(\"what are the symptom of covid-19\", 3)\n",
    "top_3_paragraphs_pyserini"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94433188",
   "metadata": {},
   "source": [
    "### 5. Paragraphs summarization (Wei's code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "addf82be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "model_name = \"t5-base\"\n",
    "tokenizer_sum = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "# Initializa Pipeline\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "889c6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(paragraphs):\n",
    "  max_length = 1024\n",
    "\n",
    "  # to store the summaries of each paragraph\n",
    "  summaries = []\n",
    "\n",
    "  for paragraph in paragraphs:\n",
    "      # devide the paragraph into sub-paragraphs\n",
    "      sub_paragraphs = re.findall(\".{1,%d}\" % max_length, paragraph)\n",
    "      sub_summaries = summarizer(sub_paragraphs, max_length=250, min_length=10, do_sample=False);\n",
    "      # concatenate the sub-paragraphs into one paragraph\n",
    "      summary = \" \".join([s[\"summary_text\"] for s in sub_summaries])\n",
    "\n",
    "      summaries.append(summary)\n",
    "      merged_summary = \" \".join(summaries)\n",
    "    \n",
    "  tokenizer_sum = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "  \n",
    "  # if merged_summary has more than 512 tokens, then we only get the first 500 tokens\n",
    "  if len(tokenizer_sum.encode(merged_summary)) > 512:\n",
    "    merged_summary = tokenizer_sum.decode(tokenizer_sum.encode(merged_summary)[:400])\n",
    "\n",
    "  text = merged_summary\n",
    "  tokens = tokenizer_sum.encode(text)\n",
    "  num_tokens = len(tokens)\n",
    "  return merged_summary, num_tokens\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62670dd1",
   "metadata": {},
   "source": [
    "### 6. Bert QA system (Jack's code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30059067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the bert model for question answering\n",
    "model_qa = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer_qa = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bffbce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in-text reference: [1]\n",
    "# function: get the answer to the question from the paragraph\n",
    "# question: the question\n",
    "# answer_text: the paragraph that contains the answer\n",
    "# output: answer\n",
    "def answer_question(question, answer_text):\n",
    "    # Apply the tokenizer to the input question and reference text\n",
    "    input_ids = tokenizer_qa.encode(question, answer_text)\n",
    "\n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_index = input_ids.index(tokenizer_qa.sep_token_id)\n",
    "\n",
    "    # The number of segment A tokens includes the [SEP] token istelf.\n",
    "    num_seg_a = sep_index + 1\n",
    "\n",
    "    # The remainder are segment B.\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # Construct the list of 0s and 1s.\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    # There should be a segment_id for every input token.\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "    # Run the model and gather the ouput tensors.\n",
    "    outputs = model_qa(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                    token_type_ids=torch.tensor([segment_ids]), # The segment IDs to differentiate question from answer_text\n",
    "                    return_dict=True) \n",
    "\n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "\n",
    "    # Find the tokens with the highest `start` and `end` scores.\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "\n",
    "    # Get the string versions of the input tokens.\n",
    "    tokens = tokenizer_qa.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # Start with the first token.\n",
    "    answer = tokens[answer_start]\n",
    "\n",
    "    # Select the remaining answer tokens and join them with whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        \n",
    "        # If it's a subword token, then recombine it with the previous token.\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        # Otherwise, add a space then the token.\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "\n",
    "    # if contains [CLS] or [SEP], then return no answer\n",
    "    if '[CLS]' in answer or '[SEP]' in answer:\n",
    "        return \"No answer\"\n",
    "    return answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7279e8a5",
   "metadata": {},
   "source": [
    "### 7. Integrated QA system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86a9de5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nausea , eye pain , loss of appetite , cutaneous rush , and hypothermia',\n",
       " 'fever was the most reported with 98.6%, followed by dry cough (88.7%), dyspnea (71,8%), fatigue (57%), desaturation (35.2%), headache (32,4%), diarrhea (30.3%), and myalgia (25.4%) others, nonrelated with covid-19, were remembered as nausea, eye pain, loss of appetite, cutaneous rush, and hypothermia . Among the 314 symptomatic individuals, the most frequent symptoms were cough (n =93, 29.6%), headaches (n=85, 27.1%), runny nose (n >79, 25.2%), unusual fatigue (n65, 20.7%), fever (n>58, 18.5%), and sore throat (n 49, 15.6%). bob greene: fever or chills, Cough, Shortness of breath or difficulty breathing, Fatigue, Muscle or body aches, Headache, New loss of taste or smell, Sore throat, Congestion or runny nose, Nausea or vomiting, Diarrhea, I do not know, he says.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function: using the word-emebdding method to get the answer to the question\n",
    "def get_answer_a2(question):\n",
    "    # preprocess the query\n",
    "    preprocessed_query = preprocess_query(question)\n",
    "    # get the top 3 paragraphs\n",
    "    paragraph_df = get_top_n_paragraphs_wb(preprocessed_query, df_paragraphs, inverted_index, 3)\n",
    "    # turn the text column into a list\n",
    "    paragraph_list = paragraph_df[\"text\"].tolist()\n",
    "    # get the summary\n",
    "    summary, token_nums = get_summary(paragraph_list)\n",
    "    # get the answer\n",
    "    return [answer_question(question, summary), summary]\n",
    "\n",
    "\n",
    "get_answer_a2(\"what are the symptoms of covid-19?\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02fd7a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wuhan city of china',\n",
       " 'genetic studies conducted during the regional spread of the virus revealed that it has a 70-79% genetic similarity to the severe acute respiratory syndrome coronavirus (SARS-CoV) that caused a serious outbreak in 2003 . in a short period of time, Thailand and Japan, the regional neighbors of China, became the first other countries where the disease was seen . SARS-CoV-2 is 96.2% similar to coronaviruses found in bats . it is not possible to speak clearly about the source of the disease since the Wuhan seafood market does not sell bats or bat meat . the global epidemic of novel coronavirus (nCoV) began in Wuhan, china . within four months, the disease was reported from more than 180 countries . the disease is related to sARS-CoV-1, 5,10,11 which led the ivc . clinically, the disease spectrum ranges from mild respiratory tract illness (self-limiting), severe pneumonia, organ failure and death. pandemic has already infected nearly 21.83 million people worldwide as of 15 th august 2020 and causing a devastating death toll of about 7,73,122 people . it has its origin in the mid-december 2019 from the west district of southern china seafood wholesale market in Wuhan city of china . more than 50 patients were rapidly infected with symptoms of cough, fever, dyspnoea with acute respiratory distress syndrome . by early January 2020, the national health commission of china provided the details of the disease spread . these strains exhibited more than 80% homology with severe acute respiratory syndrome coronavirus (SARS-CoV) and 50% similarity with that of the Middle East respiratory syndrome . the status of the COVID-19 spread to be a pandemic on 11 th March 2020 . 114 countries affected with more than 118,000 cases with a death count of 4000 .']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function: using the pyserini method to get the answer to the question\n",
    "def get_answer_a3(question):\n",
    "    # preprocess the query\n",
    "    preprocessed_query = preprocess_query(question)\n",
    "    # get the top 3 paragraphs using pyserini\n",
    "    top_3_paragraphs = get_top_n_paragraphs_pyserini(preprocessed_query, 3)\n",
    "    # get the summary of the top 3 paragraphs\n",
    "    summary, token_nums = get_summary(top_3_paragraphs)\n",
    "    # answer the question\n",
    "    return [answer_question(question, summary), summary]\n",
    "\n",
    "\n",
    "get_answer_a3(\"where is the origin of COVID-19?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4607746",
   "metadata": {},
   "source": [
    "### 8. Test utility and test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "edae7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the test queries set \n",
    "test_set = [\n",
    "    \"what is the origin of COVID-19?\",\n",
    "    \"Which city is the origin of COVID-19?\",\n",
    "    \"what types of rapid testing for Covid-19 have been developed?\",\n",
    "    \"has social distancing had an impact on slowing the spread of COVID-19?\",\n",
    "    \"what are the transmission routes of coronavirus?\",\n",
    "    \"what are the best masks for preventing infection by Covid-19?\",\n",
    "    \"what type of hand sanitizer is needed to destroy Covid-19?\",\n",
    "    \"What vaccine candidates are being tested for Covid-19?\",\n",
    "    \"does Vitamin D impact COVID-19 prevention and treatment?\",\n",
    "    \"how long can the coronavirus live outside the body?\",\n",
    "    \"what are the initial symptoms of Covid-19?\",\n",
    "    \"which biomarkers predict the severe clinical course of 2019-nCOV infection?\",\n",
    "    \"What is the result of phylogenetic analysis of SARS-CoV-2 genome sequence?\",\n",
    "    \"what are best practices in hospitals and at home in maintaining quarantine?\",\n",
    "    \"how much percentage of persons infected with SARS-CoV-2 might be asymptomatic?\",\n",
    "    \"Does COVID-19 have a higher transmission rate than SARS and middle east respiratory syndrome?\",\n",
    "    \"What is the short form for coronavirus disease 2019?\",\n",
    "    \"Why was covid-19 originally called SARS-CoV-2?\",\n",
    "    \"What is the percentage of genetic similarity between covid-19 and the severe acute respiratory syndrome coronavirus (SARS-CoV)\",\n",
    "    \"which contries became the first other countries where COVID-19 was seen?\",\n",
    "    \"What are the vaccine candidates being developed to bring the pandemic under control?\", \n",
    "    \"can available vaccines for SARS bring rapid contrl of the current pandemic?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9eebcaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_results = []\n",
    "\n",
    "# loop through the test set\n",
    "for query in test_set:\n",
    "    result = {}\n",
    "    result[\"query\"] = query\n",
    "    result[\"answer_a2\"] = get_answer_a2(query)[0]\n",
    "    result[\"answer_a3\"] = get_answer_a3(query)[0]\n",
    "    QA_results.append(result)\n",
    "\n",
    "# convert the results to a dataframe\n",
    "QA_results_df = pd.DataFrame(QA_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b18be82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_395f2_row0_col0, #T_395f2_row0_col1, #T_395f2_row0_col2, #T_395f2_row1_col0, #T_395f2_row1_col1, #T_395f2_row1_col2, #T_395f2_row2_col0, #T_395f2_row2_col1, #T_395f2_row2_col2, #T_395f2_row3_col0, #T_395f2_row3_col1, #T_395f2_row3_col2, #T_395f2_row4_col0, #T_395f2_row4_col1, #T_395f2_row4_col2, #T_395f2_row5_col0, #T_395f2_row5_col1, #T_395f2_row5_col2, #T_395f2_row6_col0, #T_395f2_row6_col1, #T_395f2_row6_col2, #T_395f2_row7_col0, #T_395f2_row7_col1, #T_395f2_row7_col2, #T_395f2_row8_col0, #T_395f2_row8_col1, #T_395f2_row8_col2, #T_395f2_row9_col0, #T_395f2_row9_col1, #T_395f2_row9_col2, #T_395f2_row10_col0, #T_395f2_row10_col1, #T_395f2_row10_col2, #T_395f2_row11_col0, #T_395f2_row11_col1, #T_395f2_row11_col2, #T_395f2_row12_col0, #T_395f2_row12_col1, #T_395f2_row12_col2, #T_395f2_row13_col0, #T_395f2_row13_col1, #T_395f2_row13_col2, #T_395f2_row14_col0, #T_395f2_row14_col1, #T_395f2_row14_col2, #T_395f2_row15_col0, #T_395f2_row15_col1, #T_395f2_row15_col2, #T_395f2_row16_col0, #T_395f2_row16_col1, #T_395f2_row16_col2, #T_395f2_row17_col0, #T_395f2_row17_col1, #T_395f2_row17_col2, #T_395f2_row18_col0, #T_395f2_row18_col1, #T_395f2_row18_col2, #T_395f2_row19_col0, #T_395f2_row19_col1, #T_395f2_row19_col2, #T_395f2_row20_col0, #T_395f2_row20_col1, #T_395f2_row20_col2, #T_395f2_row21_col0, #T_395f2_row21_col1, #T_395f2_row21_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_395f2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_395f2_level0_col0\" class=\"col_heading level0 col0\" >query</th>\n",
       "      <th id=\"T_395f2_level0_col1\" class=\"col_heading level0 col1\" >answer_a2</th>\n",
       "      <th id=\"T_395f2_level0_col2\" class=\"col_heading level0 col2\" >answer_a3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_395f2_row0_col0\" class=\"data row0 col0\" >what is the origin of COVID-19?</td>\n",
       "      <td id=\"T_395f2_row0_col1\" class=\"data row0 col1\" >huanan animal market</td>\n",
       "      <td id=\"T_395f2_row0_col2\" class=\"data row0 col2\" >west district of southern china seafood wholesale market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_395f2_row1_col0\" class=\"data row1 col0\" >Which city is the origin of COVID-19?</td>\n",
       "      <td id=\"T_395f2_row1_col1\" class=\"data row1 col1\" >huanan</td>\n",
       "      <td id=\"T_395f2_row1_col2\" class=\"data row1 col2\" >wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_395f2_row2_col0\" class=\"data row2 col0\" >what types of rapid testing for Covid-19 have been developed?</td>\n",
       "      <td id=\"T_395f2_row2_col1\" class=\"data row2 col1\" >rapid diagnostic test ( rdt ) , chemiluminescent immunoassay ( cia ) , enzymelinked immunosorbent assay ( elisa ) , and neutralization assay</td>\n",
       "      <td id=\"T_395f2_row2_col2\" class=\"data row2 col2\" >No answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_395f2_row3_col0\" class=\"data row3 col0\" >has social distancing had an impact on slowing the spread of COVID-19?</td>\n",
       "      <td id=\"T_395f2_row3_col1\" class=\"data row3 col1\" >many countries implemented statewide social distancing measures and other preventive interventions .</td>\n",
       "      <td id=\"T_395f2_row3_col2\" class=\"data row3 col2\" >public health authorities have recommended social distancing and even quarantine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_395f2_row4_col0\" class=\"data row4 col0\" >what are the transmission routes of coronavirus?</td>\n",
       "      <td id=\"T_395f2_row4_col1\" class=\"data row4 col1\" >droplet and contact transmission</td>\n",
       "      <td id=\"T_395f2_row4_col2\" class=\"data row4 col2\" >contact , droplets , airborne , fomite , fecal - oral , bloodborne , mother - to - child , and animalto - human transmission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_395f2_row5_col0\" class=\"data row5 col0\" >what are the best masks for preventing infection by Covid-19?</td>\n",
       "      <td id=\"T_395f2_row5_col1\" class=\"data row5 col1\" >surgical face masks</td>\n",
       "      <td id=\"T_395f2_row5_col2\" class=\"data row5 col2\" >triple layer surgical masks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_395f2_row6_col0\" class=\"data row6 col0\" >what type of hand sanitizer is needed to destroy Covid-19?</td>\n",
       "      <td id=\"T_395f2_row6_col1\" class=\"data row6 col1\" >No answer</td>\n",
       "      <td id=\"T_395f2_row6_col2\" class=\"data row6 col2\" >alcohol based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_395f2_row7_col0\" class=\"data row7 col0\" >What vaccine candidates are being tested for Covid-19?</td>\n",
       "      <td id=\"T_395f2_row7_col1\" class=\"data row7 col1\" >mrna and viral vector vaccines</td>\n",
       "      <td id=\"T_395f2_row7_col2\" class=\"data row7 col2\" >two mrna vaccines of bnt162b2 ( pfizer / biontech ) and mdna - 1273 ( moderna )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_395f2_row8_col0\" class=\"data row8 col0\" >does Vitamin D impact COVID-19 prevention and treatment?</td>\n",
       "      <td id=\"T_395f2_row8_col1\" class=\"data row8 col1\" >rapid vaccine development using the mrna platform is mitigating covid - 19 hospitalizations and deaths</td>\n",
       "      <td id=\"T_395f2_row8_col2\" class=\"data row8 col2\" >potential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_395f2_row9_col0\" class=\"data row9 col0\" >how long can the coronavirus live outside the body?</td>\n",
       "      <td id=\"T_395f2_row9_col1\" class=\"data row9 col1\" >several hours</td>\n",
       "      <td id=\"T_395f2_row9_col2\" class=\"data row9 col2\" >up to 60 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_395f2_row10_col0\" class=\"data row10 col0\" >what are the initial symptoms of Covid-19?</td>\n",
       "      <td id=\"T_395f2_row10_col1\" class=\"data row10 col1\" >nausea , eye pain , loss of appetite , cutaneous rush , and hypothermia</td>\n",
       "      <td id=\"T_395f2_row10_col2\" class=\"data row10 col2\" >runny nose , sore throat , dry cough , muscle / joint pain , loss of taste / smell , shortness of breath , fever , chills / shaking , diarrhea , nausea / vomiting , fatigue and / or headache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_395f2_row11_col0\" class=\"data row11 col0\" >which biomarkers predict the severe clinical course of 2019-nCOV infection?</td>\n",
       "      <td id=\"T_395f2_row11_col1\" class=\"data row11 col1\" >transthoracic echocardiogram</td>\n",
       "      <td id=\"T_395f2_row11_col2\" class=\"data row11 col2\" >ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_395f2_row12_col0\" class=\"data row12 col0\" >What is the result of phylogenetic analysis of SARS-CoV-2 genome sequence?</td>\n",
       "      <td id=\"T_395f2_row12_col1\" class=\"data row12 col1\" >analysis of 17271 genomes</td>\n",
       "      <td id=\"T_395f2_row12_col2\" class=\"data row12 col2\" >80 % identity to sars - cov - 1 and 50 % identity to mers - cov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_395f2_row13_col0\" class=\"data row13 col0\" >what are best practices in hospitals and at home in maintaining quarantine?</td>\n",
       "      <td id=\"T_395f2_row13_col1\" class=\"data row13 col1\" >if symptoms appear , get covid testing done</td>\n",
       "      <td id=\"T_395f2_row13_col2\" class=\"data row13 col2\" >home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_395f2_row14_col0\" class=\"data row14 col0\" >how much percentage of persons infected with SARS-CoV-2 might be asymptomatic?</td>\n",
       "      <td id=\"T_395f2_row14_col1\" class=\"data row14 col1\" >19 . 5 %</td>\n",
       "      <td id=\"T_395f2_row14_col2\" class=\"data row14 col2\" >> 40 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_395f2_row15_col0\" class=\"data row15 col0\" >Does COVID-19 have a higher transmission rate than SARS and middle east respiratory syndrome?</td>\n",
       "      <td id=\"T_395f2_row15_col1\" class=\"data row15 col1\" >it had a high genomic similarity with its predecessor , severe acute respiratory syndrome coronalvirus ( sars - cov ) , compared with the middle east respiratory syndrome virus ( mers - cov )</td>\n",
       "      <td id=\"T_395f2_row15_col2\" class=\"data row15 col2\" >covid - 19 has a higher transmission rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_395f2_row16_col0\" class=\"data row16 col0\" >What is the short form for coronavirus disease 2019?</td>\n",
       "      <td id=\"T_395f2_row16_col1\" class=\"data row16 col1\" >covid - 19</td>\n",
       "      <td id=\"T_395f2_row16_col2\" class=\"data row16 col2\" >covid - 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_395f2_row17_col0\" class=\"data row17 col0\" >Why was covid-19 originally called SARS-CoV-2?</td>\n",
       "      <td id=\"T_395f2_row17_col1\" class=\"data row17 col1\" >severe acute respiratory syndrome</td>\n",
       "      <td id=\"T_395f2_row17_col2\" class=\"data row17 col2\" >it represents the most recent introduction of a high pathogenic coronevirus into the human population</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_395f2_row18_col0\" class=\"data row18 col0\" >What is the percentage of genetic similarity between covid-19 and the severe acute respiratory syndrome coronavirus (SARS-CoV)</td>\n",
       "      <td id=\"T_395f2_row18_col1\" class=\"data row18 col1\" >what is the percentage of genetic similarity</td>\n",
       "      <td id=\"T_395f2_row18_col2\" class=\"data row18 col2\" >70 - 79 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_395f2_row19_col0\" class=\"data row19 col0\" >which contries became the first other countries where COVID-19 was seen?</td>\n",
       "      <td id=\"T_395f2_row19_col1\" class=\"data row19 col1\" >china</td>\n",
       "      <td id=\"T_395f2_row19_col2\" class=\"data row19 col2\" >thailand and japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_395f2_row20_col0\" class=\"data row20 col0\" >What are the vaccine candidates being developed to bring the pandemic under control?</td>\n",
       "      <td id=\"T_395f2_row20_col1\" class=\"data row20 col1\" >adenovirus and rna - based vaccines that have been developed against sars - cov - 2</td>\n",
       "      <td id=\"T_395f2_row20_col2\" class=\"data row20 col2\" >two mrna vaccines of bnt162b2 ( pfizer / biontech ) and mdna - 1273 ( moderna )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_395f2_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_395f2_row21_col0\" class=\"data row21 col0\" >can available vaccines for SARS bring rapid contrl of the current pandemic?</td>\n",
       "      <td id=\"T_395f2_row21_col1\" class=\"data row21 col1\" >the pandemic has spurred the rapid development of several vaccines</td>\n",
       "      <td id=\"T_395f2_row21_col2\" class=\"data row21 col2\" >unlikely to bring rapid control of the current pandemic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc688a5a940>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# present the results in a better way\n",
    "QA_results_df.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5360534b",
   "metadata": {},
   "source": [
    "#### 5.1 result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dfd14f",
   "metadata": {},
   "source": [
    "After obtaining the test results, we will manually identify the correctness of each return snippets and calculate the reciprocal rank for each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac2c1942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>answer_a2</th>\n",
       "      <th>answer_a3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the origin of COVID-19?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which city is the origin of COVID-19?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what types of rapid testing for Covid-19 have ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>has social distancing had an impact on slowing...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are the transmission routes of coronavirus?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>what are the best masks for preventing infecti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what type of hand sanitizer is needed to destr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What vaccine candidates are being tested for C...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>does Vitamin D impact COVID-19 prevention and ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how long can the coronavirus live outside the ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>what are the initial symptoms of Covid-19?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>which biomarkers predict the severe clinical c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What is the result of phylogenetic analysis of...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>what are best practices in hospitals and at ho...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>how much percentage of persons infected with S...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Does COVID-19 have a higher transmission rate ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What is the short form for coronavirus disease...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Why was covid-19 originally called SARS-CoV-2?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What is the percentage of genetic similarity b...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>which contries became the first other countrie...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What are the vaccine candidates being develope...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>can available vaccines for SARS bring rapid co...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  answer_a2  answer_a3\n",
       "0                     what is the origin of COVID-19?        1.0          1\n",
       "1               Which city is the origin of COVID-19?        0.0          1\n",
       "2   what types of rapid testing for Covid-19 have ...        1.0          0\n",
       "3   has social distancing had an impact on slowing...        0.0          0\n",
       "4    what are the transmission routes of coronavirus?        0.5          1\n",
       "5   what are the best masks for preventing infecti...        1.0          1\n",
       "6   what type of hand sanitizer is needed to destr...        0.0          1\n",
       "7   What vaccine candidates are being tested for C...        1.0          1\n",
       "8   does Vitamin D impact COVID-19 prevention and ...        0.0          0\n",
       "9   how long can the coronavirus live outside the ...        0.0          1\n",
       "10         what are the initial symptoms of Covid-19?        0.5          1\n",
       "11  which biomarkers predict the severe clinical c...        0.0          0\n",
       "12  What is the result of phylogenetic analysis of...        0.0          1\n",
       "13  what are best practices in hospitals and at ho...        0.5          0\n",
       "14  how much percentage of persons infected with S...        0.0          1\n",
       "15  Does COVID-19 have a higher transmission rate ...        0.0          1\n",
       "16  What is the short form for coronavirus disease...        1.0          1\n",
       "17     Why was covid-19 originally called SARS-CoV-2?        0.0          0\n",
       "18  What is the percentage of genetic similarity b...        0.0          1\n",
       "19  which contries became the first other countrie...        0.0          1\n",
       "20  What are the vaccine candidates being develope...        0.0          1\n",
       "21  can available vaccines for SARS bring rapid co...        0.0          1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct the results\n",
    "\n",
    "result = [\n",
    "    {\"query\": \"what is the origin of COVID-19?\", \"answer_a2\": 1, \"answer_a3\": 1},\n",
    "    {\"query\": \"Which city is the origin of COVID-19?\", \"answer_a2\": 0, \"answer_a3\": 1},\n",
    "    {\"query\": \"what types of rapid testing for Covid-19 have been developed?\", \"answer_a2\": 1, \"answer_a3\": 0},\n",
    "    {\"query\": \"has social distancing had an impact on slowing the spread of COVID-19?\", \"answer_a2\": 0, \"answer_a3\": 0},\n",
    "    {\"query\": \"what are the transmission routes of coronavirus?\", \"answer_a2\": 0.5, \"answer_a3\": 1},\n",
    "    {\"query\": \"what are the best masks for preventing infection by Covid-19?\", \"answer_a2\": 1, \"answer_a3\": 1},\n",
    "    {\"query\": \"what type of hand sanitizer is needed to destroy Covid-19?\", \"answer_a2\": 0, \"answer_a3\": 1},\n",
    "    {\"query\": \"What vaccine candidates are being tested for Covid-19?\", \"answer_a2\": 1, \"answer_a3\": 1},\n",
    "    {\"query\": \"does Vitamin D impact COVID-19 prevention and treatment?\", \"answer_a2\": 0, \"answer_a3\": 0},\n",
    "    {\"query\": \"how long can the coronavirus live outside the body?\", \"answer_a2\": 0, \"answer_a3\": 1},\n",
    "    {\"query\": \"what are the initial symptoms of Covid-19?\", \"answer_a2\": 0.5, \"answer_a3\": 1},\n",
    "    {\"query\": \"which biomarkers predict the severe clinical course of 2019-nCOV infection?\", \"answer_a2\": 0, \"answer_a3\": 0},\n",
    "    {\"query\": \"What is the result of phylogenetic analysis of SARS-CoV-2 genome sequence?\", \"answer_a2\": 0, \"answer_a3\": 1},\n",
    "    {\"query\": \"what are best practices in hospitals and at home in maintaining quarantine?\", \"answer_a2\": 0.5, \"answer_a3\": 0},\n",
    "    {\"query\": \"how much percentage of persons infected with SARS-CoV-2 might be asymptomatic?\", \"answer_a2\": 0, \"answer_a3\": 1},\n",
    "    {\"query\": \"Does COVID-19 have a higher transmission rate than SARS and middle east respiratory syndrome?\", \"answer_a2\": 0, \"answer_a3\": 1},\n",
    "    {\"query\": \"What is the short form for coronavirus disease 2019?\", \"answer_a2\": 1, \"answer_a3\": 1},\n",
    "    {\"query\": \"Why was covid-19 originally called SARS-CoV-2?\", \"answer_a2\": 0, \"answer_a3\": 0},\n",
    "    {\"query\": \"What is the percentage of genetic similarity between covid-19 and the severe acute respiratory syndrome coronavirus (SARS-CoV)\", \"answer_a2\": 0, \"answer_a3\": 1},\n",
    "    {\"query\": \"which contries became the first other countries where COVID-19 was seen?\", \"answer_a2\": 0, \"answer_a3\": 1},\n",
    "    {\"query\": \"What are the vaccine candidates being developed to bring the pandemic under control?\",  \"answer_a2\": 0, \"answer_a3\": 1},\n",
    "    {\"query\": \"can available vaccines for SARS bring rapid contrl of the current pandemic?\", \"answer_a2\": 0, \"answer_a3\": 1},\n",
    "]\n",
    "\n",
    "# convert the results to a dataframe\n",
    "result_df = pd.DataFrame(result)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# present the results in a better way\n",
    "# make a copy of the QA_results_df\n",
    "QA_results_df_copy = QA_results_df.copy()\n",
    "\n",
    "for i in range(len(QA_results_df_copy)):\n",
    "    QA_results_df_copy.at[i, \"answer_a2\"] = [QA_results_df_copy.at[i, \"answer_a2\"], result_df.at[i, \"answer_a2\"]]\n",
    "    QA_results_df_copy.at[i, \"answer_a3\"] = [QA_results_df_copy.at[i, \"answer_a3\"], result_df.at[i, \"answer_a3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5f96fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the answer_a2 column name to answer_word_embedding\n",
    "QA_results_df_copy.rename(columns={\"answer_a2\": \"answer_word_embedding\"}, inplace=True)\n",
    "\n",
    "# change the answer_a3 column name to answer_pyserini\n",
    "QA_results_df_copy.rename(columns={\"answer_a3\": \"answer_pyserini\"}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb9ba458",
   "metadata": {},
   "source": [
    "To shows the result more clearly, we will plot the answers with different colors. The correct answers are shown in yellow, the half correct answers are shown in white, and the incorrect answers are shown in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7973baca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_52da9_row0_col0, #T_52da9_row1_col0, #T_52da9_row2_col0, #T_52da9_row3_col0, #T_52da9_row4_col0, #T_52da9_row5_col0, #T_52da9_row6_col0, #T_52da9_row7_col0, #T_52da9_row8_col0, #T_52da9_row9_col0, #T_52da9_row10_col0, #T_52da9_row11_col0, #T_52da9_row12_col0, #T_52da9_row13_col0, #T_52da9_row14_col0, #T_52da9_row15_col0, #T_52da9_row16_col0, #T_52da9_row17_col0, #T_52da9_row18_col0, #T_52da9_row19_col0, #T_52da9_row20_col0, #T_52da9_row21_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_52da9_row0_col1, #T_52da9_row0_col2, #T_52da9_row1_col2, #T_52da9_row2_col1, #T_52da9_row4_col2, #T_52da9_row5_col1, #T_52da9_row5_col2, #T_52da9_row6_col2, #T_52da9_row7_col1, #T_52da9_row7_col2, #T_52da9_row9_col2, #T_52da9_row10_col2, #T_52da9_row12_col2, #T_52da9_row14_col2, #T_52da9_row15_col2, #T_52da9_row16_col1, #T_52da9_row16_col2, #T_52da9_row18_col2, #T_52da9_row19_col2, #T_52da9_row20_col2, #T_52da9_row21_col2 {\n",
       "  color: yellow;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_52da9_row1_col1, #T_52da9_row2_col2, #T_52da9_row3_col1, #T_52da9_row3_col2, #T_52da9_row6_col1, #T_52da9_row8_col1, #T_52da9_row8_col2, #T_52da9_row9_col1, #T_52da9_row11_col1, #T_52da9_row11_col2, #T_52da9_row12_col1, #T_52da9_row13_col2, #T_52da9_row14_col1, #T_52da9_row15_col1, #T_52da9_row17_col1, #T_52da9_row17_col2, #T_52da9_row18_col1, #T_52da9_row19_col1, #T_52da9_row20_col1, #T_52da9_row21_col1 {\n",
       "  color: red;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_52da9_row4_col1, #T_52da9_row10_col1, #T_52da9_row13_col1 {\n",
       "  color: white;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_52da9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_52da9_level0_col0\" class=\"col_heading level0 col0\" >query</th>\n",
       "      <th id=\"T_52da9_level0_col1\" class=\"col_heading level0 col1\" >answer_word_embedding</th>\n",
       "      <th id=\"T_52da9_level0_col2\" class=\"col_heading level0 col2\" >answer_pyserini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_52da9_row0_col0\" class=\"data row0 col0\" >what is the origin of COVID-19?</td>\n",
       "      <td id=\"T_52da9_row0_col1\" class=\"data row0 col1\" >['huanan animal market', 1.0]</td>\n",
       "      <td id=\"T_52da9_row0_col2\" class=\"data row0 col2\" >['west district of southern china seafood wholesale market', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_52da9_row1_col0\" class=\"data row1 col0\" >Which city is the origin of COVID-19?</td>\n",
       "      <td id=\"T_52da9_row1_col1\" class=\"data row1 col1\" >['huanan', 0.0]</td>\n",
       "      <td id=\"T_52da9_row1_col2\" class=\"data row1 col2\" >['wuhan', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_52da9_row2_col0\" class=\"data row2 col0\" >what types of rapid testing for Covid-19 have been developed?</td>\n",
       "      <td id=\"T_52da9_row2_col1\" class=\"data row2 col1\" >['rapid diagnostic test ( rdt ) , chemiluminescent immunoassay ( cia ) , enzymelinked immunosorbent assay ( elisa ) , and neutralization assay', 1.0]</td>\n",
       "      <td id=\"T_52da9_row2_col2\" class=\"data row2 col2\" >['No answer', 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_52da9_row3_col0\" class=\"data row3 col0\" >has social distancing had an impact on slowing the spread of COVID-19?</td>\n",
       "      <td id=\"T_52da9_row3_col1\" class=\"data row3 col1\" >['many countries implemented statewide social distancing measures and other preventive interventions .', 0.0]</td>\n",
       "      <td id=\"T_52da9_row3_col2\" class=\"data row3 col2\" >['public health authorities have recommended social distancing and even quarantine', 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_52da9_row4_col0\" class=\"data row4 col0\" >what are the transmission routes of coronavirus?</td>\n",
       "      <td id=\"T_52da9_row4_col1\" class=\"data row4 col1\" >['droplet and contact transmission', 0.5]</td>\n",
       "      <td id=\"T_52da9_row4_col2\" class=\"data row4 col2\" >['contact , droplets , airborne , fomite , fecal - oral , bloodborne , mother - to - child , and animalto - human transmission', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_52da9_row5_col0\" class=\"data row5 col0\" >what are the best masks for preventing infection by Covid-19?</td>\n",
       "      <td id=\"T_52da9_row5_col1\" class=\"data row5 col1\" >['surgical face masks', 1.0]</td>\n",
       "      <td id=\"T_52da9_row5_col2\" class=\"data row5 col2\" >['triple layer surgical masks', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_52da9_row6_col0\" class=\"data row6 col0\" >what type of hand sanitizer is needed to destroy Covid-19?</td>\n",
       "      <td id=\"T_52da9_row6_col1\" class=\"data row6 col1\" >['No answer', 0.0]</td>\n",
       "      <td id=\"T_52da9_row6_col2\" class=\"data row6 col2\" >['alcohol based', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_52da9_row7_col0\" class=\"data row7 col0\" >What vaccine candidates are being tested for Covid-19?</td>\n",
       "      <td id=\"T_52da9_row7_col1\" class=\"data row7 col1\" >['mrna and viral vector vaccines', 1.0]</td>\n",
       "      <td id=\"T_52da9_row7_col2\" class=\"data row7 col2\" >['two mrna vaccines of bnt162b2 ( pfizer / biontech ) and mdna - 1273 ( moderna )', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_52da9_row8_col0\" class=\"data row8 col0\" >does Vitamin D impact COVID-19 prevention and treatment?</td>\n",
       "      <td id=\"T_52da9_row8_col1\" class=\"data row8 col1\" >['rapid vaccine development using the mrna platform is mitigating covid - 19 hospitalizations and deaths', 0.0]</td>\n",
       "      <td id=\"T_52da9_row8_col2\" class=\"data row8 col2\" >['potential', 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_52da9_row9_col0\" class=\"data row9 col0\" >how long can the coronavirus live outside the body?</td>\n",
       "      <td id=\"T_52da9_row9_col1\" class=\"data row9 col1\" >['several hours', 0.0]</td>\n",
       "      <td id=\"T_52da9_row9_col2\" class=\"data row9 col2\" >['up to 60 minutes', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_52da9_row10_col0\" class=\"data row10 col0\" >what are the initial symptoms of Covid-19?</td>\n",
       "      <td id=\"T_52da9_row10_col1\" class=\"data row10 col1\" >['nausea , eye pain , loss of appetite , cutaneous rush , and hypothermia', 0.5]</td>\n",
       "      <td id=\"T_52da9_row10_col2\" class=\"data row10 col2\" >['runny nose , sore throat , dry cough , muscle / joint pain , loss of taste / smell , shortness of breath , fever , chills / shaking , diarrhea , nausea / vomiting , fatigue and / or headache', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_52da9_row11_col0\" class=\"data row11 col0\" >which biomarkers predict the severe clinical course of 2019-nCOV infection?</td>\n",
       "      <td id=\"T_52da9_row11_col1\" class=\"data row11 col1\" >['transthoracic echocardiogram', 0.0]</td>\n",
       "      <td id=\"T_52da9_row11_col2\" class=\"data row11 col2\" >['ml', 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_52da9_row12_col0\" class=\"data row12 col0\" >What is the result of phylogenetic analysis of SARS-CoV-2 genome sequence?</td>\n",
       "      <td id=\"T_52da9_row12_col1\" class=\"data row12 col1\" >['analysis of 17271 genomes', 0.0]</td>\n",
       "      <td id=\"T_52da9_row12_col2\" class=\"data row12 col2\" >['80 % identity to sars - cov - 1 and 50 % identity to mers - cov', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_52da9_row13_col0\" class=\"data row13 col0\" >what are best practices in hospitals and at home in maintaining quarantine?</td>\n",
       "      <td id=\"T_52da9_row13_col1\" class=\"data row13 col1\" >['if symptoms appear , get covid testing done', 0.5]</td>\n",
       "      <td id=\"T_52da9_row13_col2\" class=\"data row13 col2\" >['home', 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_52da9_row14_col0\" class=\"data row14 col0\" >how much percentage of persons infected with SARS-CoV-2 might be asymptomatic?</td>\n",
       "      <td id=\"T_52da9_row14_col1\" class=\"data row14 col1\" >['19 . 5 %', 0.0]</td>\n",
       "      <td id=\"T_52da9_row14_col2\" class=\"data row14 col2\" >['> 40 %', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_52da9_row15_col0\" class=\"data row15 col0\" >Does COVID-19 have a higher transmission rate than SARS and middle east respiratory syndrome?</td>\n",
       "      <td id=\"T_52da9_row15_col1\" class=\"data row15 col1\" >['it had a high genomic similarity with its predecessor , severe acute respiratory syndrome coronalvirus ( sars - cov ) , compared with the middle east respiratory syndrome virus ( mers - cov )', 0.0]</td>\n",
       "      <td id=\"T_52da9_row15_col2\" class=\"data row15 col2\" >['covid - 19 has a higher transmission rate', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_52da9_row16_col0\" class=\"data row16 col0\" >What is the short form for coronavirus disease 2019?</td>\n",
       "      <td id=\"T_52da9_row16_col1\" class=\"data row16 col1\" >['covid - 19', 1.0]</td>\n",
       "      <td id=\"T_52da9_row16_col2\" class=\"data row16 col2\" >['covid - 19', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_52da9_row17_col0\" class=\"data row17 col0\" >Why was covid-19 originally called SARS-CoV-2?</td>\n",
       "      <td id=\"T_52da9_row17_col1\" class=\"data row17 col1\" >['severe acute respiratory syndrome', 0.0]</td>\n",
       "      <td id=\"T_52da9_row17_col2\" class=\"data row17 col2\" >['it represents the most recent introduction of a high pathogenic coronevirus into the human population', 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_52da9_row18_col0\" class=\"data row18 col0\" >What is the percentage of genetic similarity between covid-19 and the severe acute respiratory syndrome coronavirus (SARS-CoV)</td>\n",
       "      <td id=\"T_52da9_row18_col1\" class=\"data row18 col1\" >['what is the percentage of genetic similarity', 0.0]</td>\n",
       "      <td id=\"T_52da9_row18_col2\" class=\"data row18 col2\" >['70 - 79 %', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_52da9_row19_col0\" class=\"data row19 col0\" >which contries became the first other countries where COVID-19 was seen?</td>\n",
       "      <td id=\"T_52da9_row19_col1\" class=\"data row19 col1\" >['china', 0.0]</td>\n",
       "      <td id=\"T_52da9_row19_col2\" class=\"data row19 col2\" >['thailand and japan', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_52da9_row20_col0\" class=\"data row20 col0\" >What are the vaccine candidates being developed to bring the pandemic under control?</td>\n",
       "      <td id=\"T_52da9_row20_col1\" class=\"data row20 col1\" >['adenovirus and rna - based vaccines that have been developed against sars - cov - 2', 0.0]</td>\n",
       "      <td id=\"T_52da9_row20_col2\" class=\"data row20 col2\" >['two mrna vaccines of bnt162b2 ( pfizer / biontech ) and mdna - 1273 ( moderna )', 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52da9_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_52da9_row21_col0\" class=\"data row21 col0\" >can available vaccines for SARS bring rapid contrl of the current pandemic?</td>\n",
       "      <td id=\"T_52da9_row21_col1\" class=\"data row21 col1\" >['the pandemic has spurred the rapid development of several vaccines', 0.0]</td>\n",
       "      <td id=\"T_52da9_row21_col2\" class=\"data row21 col2\" >['unlikely to bring rapid control of the current pandemic', 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc4959eec10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QA_results_df_copy.style.set_properties(**{'text-align': 'left'})\n",
    "\n",
    "# change the cell color based on the score\n",
    "def color_negative_red(val):\n",
    "    if val[1] == 1:\n",
    "        color = 'yellow'\n",
    "    elif val[1] == 0:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'white'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "QA_results_df_copy.style.applymap(color_negative_red, subset=[\"answer_word_embedding\", \"answer_pyserini\"]).set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6da2daeb",
   "metadata": {},
   "source": [
    "Finally, we calculate the scores for each method. The result analysis is presented in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f80a0f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_a2 score: 29.55%\n",
      "answer_a3 score: 72.73%\n"
     ]
    }
   ],
   "source": [
    "# get the sum of the answer_a2 column\n",
    "answer_a2_score = result_df[\"answer_a2\"].sum() / len(result_df)\n",
    "\n",
    "# get the sum of the answer_a3 column\n",
    "answer_a3_score = result_df[\"answer_a3\"].sum() / len(result_df)\n",
    "\n",
    "# print the results in percentage with 2 decimal places\n",
    "print(\"answer_a2 score: {:.2%}\".format(answer_a2_score))\n",
    "print(\"answer_a3 score: {:.2%}\".format(answer_a3_score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba7ea3a2",
   "metadata": {},
   "source": [
    "### 9. Simple user interface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90212831",
   "metadata": {},
   "source": [
    "In this section, we will build a simple user interface for the QA system. The user can input a question and the system will return the answer. The user can also choose the whether to play the audio of the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26e7db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtts\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8524638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    # make request to google to get synthesis\n",
    "    tts = gtts.gTTS(text=text, lang=\"en\")\n",
    "\n",
    "    # save the audio file\n",
    "    tts.save(\"temp_audio.mp3\")\n",
    "\n",
    "    # play the audio file\n",
    "    playsound(\"temp_audio.mp3\")\n",
    "\n",
    "def QA_user_interface():\n",
    "    query = input(\"Please enter your question: \")\n",
    "    if query == \"exit\":\n",
    "        return\n",
    "    speakOrNot = input(\"Do you want to hear the answer? This requires network connection. (y/n): \")\n",
    "    answer = get_answer_a3(query)[0]\n",
    "    print(\"Question: {}\".format(query))\n",
    "    print(\"Answer: {}\".format(answer))\n",
    "    if speakOrNot == \"y\":\n",
    "        speak(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e97fa578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which city is the origin of COVID-19?\n",
      "Answer: wuhan\n"
     ]
    }
   ],
   "source": [
    "QA_user_interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a91b4",
   "metadata": {},
   "source": [
    "### 7. References"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1544e6d1",
   "metadata": {},
   "source": [
    "[1] https://www.youtube.com/watch?v=l8ZYCvgGu0o&ab_channel=ChrisMcCormickAI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-assignment1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "92c54f69d507b8df6905a9861d217c68b6bc41aff126e4d6cd7af9249ab3a638"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
